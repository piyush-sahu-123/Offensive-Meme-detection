{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"flqa8GuNfwc0"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XWT4mFWxfuCk","outputId":"369b8d4a-2a9d-4dca-b927-824fb0db1785","scrolled":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Using TensorFlow backend.\n"]}],"source":["# Importing necessary libraries\n","import keras\n","import h5py\n","from keras import optimizers\n","from keras.models import load_model\n","from keras.layers import Bidirectional\n","from Multimodal_baseline_Functions import *\n","from keras.layers.core import Reshape, Dropout\n","from keras.utils.vis_utils import plot_model\n","import os\n","# import keras_metrics\n","import matplotlib.pyplot as plt\n","from keras.layers import Conv1D, MaxPooling1D, Flatten, GlobalAveragePooling3D\n","from keras import regularizers\n","import seaborn as sns\n","import matplotlib.pyplot as plt   \n","from sklearn.metrics import confusion_matrix\n","from keras import regularizers  \n","from keras.applications.inception_v3 import InceptionV3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XH8RGgF8fuCq"},"outputs":[],"source":["class_weight = {1: 1.4,\n","                0: 1.}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jGomHPVLfuCr"},"outputs":[],"source":["GLOVE_DIR = \"./drive/MyDrive/sumaiya thaseen proj/glove.6B\"\n","EMBEDDING_DIM = 50"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z7LC6u4ufuCs"},"outputs":[],"source":["# Defining model with Adam optimizer\n","adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n","sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n","adadelta = optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fGgOf0oJfuCs"},"outputs":[],"source":["def Image_model(base_model):\n","    # Freezing all the trainable layers\n","    for layer in base_model.layers:\n","        layer.trainable = False\n","\n","    # Creating output layer\n","    x = base_model.output\n","    # Adding pooling layer before the output\n","    x = GlobalAveragePooling2D()(x)    \n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u3zjzn3yfuCt"},"outputs":[],"source":["def read_data(file_name):\n","  #Opening file\n","    with open(file_name,'r', encoding=\"utf8\") as f:\n","      #Creating empty set and dictonary for vocab and word respectively\n","        word_vocab = set() \n","        word2vector = {}\n","        #Iterating over each line of file\n","        for line in f:\n","            #Spliting lines\n","            line_ = line.strip() \n","            #Splitting words\n","            words_Vec = line_.split()            \n","            word_vocab.add(words_Vec[0])\n","            word2vector[words_Vec[0]] = np.array(words_Vec[1:],dtype=float)\n","    print(\"Total Words in DataSet:\",len(word_vocab))\n","    return word_vocab,word2vector"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jc8TVLiRfuCu"},"outputs":[],"source":["# Dividing data in test, train, validation\n","training_DF, testing_DF, validation_DF = preprocess_text(Training_path,Validation_path, Testing_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"stpUr2OhfuCw"},"outputs":[],"source":["# Processing image and text for each set\n","# Creating train, test and validation image path\n","train_img_path = create_img_path(training_DF,'image_name', img_dir)\n","test_img_path = create_img_path(testing_DF,'image_name', img_dir)\n","val_img_path = create_img_path(validation_DF,'image_name', img_dir)\n","\n","# Processing the text\n","training_DF['sentence'] = training_DF['sentence'].apply(clean_text)\n","testing_DF['sentence'] = testing_DF['sentence'].apply(clean_text)\n","validation_DF['sentence'] = validation_DF['sentence'].apply(clean_text)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FgBmAkkYfuCx"},"outputs":[],"source":["# Vectorising text\n","# process the whole observation into single list\n","train_text_list=list(training_DF['sentence'])\n","test_text_list = list(testing_DF['sentence'])\n","val_text_list = list(validation_DF['sentence'])\n","\n","# Creating vectors for train, test, validation\n","tokenizer = Tokenizer(num_words=1000)\n","tokenizer.fit_on_texts(train_text_list)\n","sequences_train = tokenizer.texts_to_sequences(train_text_list)\n","sequences_test = tokenizer.texts_to_sequences(test_text_list)\n","sequences_val = tokenizer.texts_to_sequences(val_text_list)\n","\n","x_train = preprocessing.sequence.pad_sequences(sequences_train, maxlen=maxlen)\n","x_test = preprocessing.sequence.pad_sequences(sequences_test, maxlen=maxlen)\n","x_val = preprocessing.sequence.pad_sequences(sequences_val, maxlen=maxlen)\n","\n","# encoding all the labels \n","y_test = testing_DF['label']\n","y_train = training_DF['label']\n","y_val = validation_DF['label']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DOx5A29ufuCy"},"outputs":[],"source":["# Creating train, test, val, generator for meme\n","img_txt_gen_train = img_text_generator(train_img_path, x_train, y_train, batch_size=32)\n","img_txt_gen_test = img_text_generator(test_img_path, x_test, y_test, batch_size=1)\n","img_txt_gen_val = img_text_generator(val_img_path, x_val, y_val, batch_size=1)\n","\n","# Creating train, test, val, generator for text\n","txt_gen_train = text_generator(x_train, y_train, batch_size=32)\n","txt_gen_test = text_generator(x_test, y_test, batch_size=1)\n","txt_gen_val = text_generator(x_val, y_val, batch_size=1)\n","\n","# Creating train, test, val, generator for image\n","img_gen_train = image_generator(train_img_path, training_DF, batch_size=32)\n","img_gen_test = image_generator(test_img_path, testing_DF, batch_size=1)\n","img_gen_val = image_generator(val_img_path, validation_DF, batch_size=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OnOrPSu7fuCz","outputId":"ca4d75a7-c371-4e0b-e045-ff7a9f4a0329"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total Words in DataSet: 400000\n"]}],"source":["vocab, w2v = read_data(os.path.join(GLOVE_DIR, \"glove.6B.50d.txt\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cqo4iyLefuC0"},"outputs":[],"source":["word_index = tokenizer.word_index\n","num_tokens = len(word_index)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EKYIfl_4fuC1"},"outputs":[],"source":["#Creating embeddding weight matrix\n","embedding_matrix = np.zeros((num_tokens + 1, EMBEDDING_DIM))\n","\n","for word, i in word_index.items():\n","    embedding_vector = w2v.get(word)\n","    if embedding_vector is not None:\n","        embedding_matrix[i] = embedding_vector"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OCuiwI4kfuC1","outputId":"5949de24-fb44-4bfa-fa53-cfb19e5383e5"},"outputs":[],"source":["#Creating embedded layer using embedded matrix as weight matrix\n","embedding_layer = Embedding(num_tokens + 1, EMBEDDING_DIM, weights=[embedding_matrix], trainable = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D9Jd22FEfuC2","outputId":"35335fc8-fc30-4dd7-b887-f4a489ba6b8f"},"outputs":[],"source":["# Defining input layer\n","main_input = Input(shape=(maxlen,), dtype='int32', name='main_input')\n","\n","# Defining embedding layer which will encode the input sequence\n","embedded_sequences = embedding_layer(main_input)\n","# x = Embedding(output_dim=512, input_dim=10000, input_length=maxlen)(main_input)\n","\n","# A LSTM will transform the vector sequence into a single vector,\n","# containing information about the entire sequence\n","lstm_out = (Bidirectional(LSTM(32)))(embedded_sequences)\n","\n","# Output of text model\n","txt_out = Dense(1, activation='sigmoid')(lstm_out)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fuo7X_hHfuC2"},"outputs":[],"source":["txt_model = Model(inputs = [main_input], outputs=txt_out)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EUpXXCXmfuC3","outputId":"4802f4de-d12f-49e9-dca7-12b188b6005c","scrolled":true},"outputs":[],"source":["txt_model.compile(loss='binary_crossentropy', optimizer=adam, metrics = [\"accuracy\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M7A1baJJfuC3"},"outputs":[],"source":["plot_model(txt_model, to_file='BiLSTM_txt_model.png', show_shapes=True, show_layer_names=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qp7g1w0NfuC3","outputId":"b5821f42-f783-416b-c53a-35fea3bd0197"},"outputs":[],"source":["# Training text model\n","txt_model.fit_generator(txt_gen_train, epochs=7, validation_steps = 149, steps_per_epoch=2, validation_data=txt_gen_val, shuffle = False, class_weight=class_weight)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jnd4UJEIfuC4"},"outputs":[],"source":["txt_model.save('BiLSTM_txt_model.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nIBItxPofuC4"},"outputs":[],"source":["y_pred_txt = (txt_model.predict_generator(txt_gen_test,steps = 149))\n","y_pred_txt = np.round(list(itertools.chain(*y_pred_txt)))\n","y_true = y_test.values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s_uMOH-8fuC5","outputId":"618ec7a5-6b55-4988-e48b-5cfb54a83e83"},"outputs":[],"source":["labels = [1,0]\n","cm = confusion_matrix(y_true, y_pred_txt, labels)\n","ax= plt.subplot()\n","sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n","\n","# labels, title and ticks\n","ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n","ax.set_title('Confusion Matrix'); \n","ax.xaxis.set_ticklabels(['offensive', 'non-offensive']); ax.yaxis.set_ticklabels(['offensive', 'non-offensive']);"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pi3V-X25fuC5","outputId":"66046328-14aa-467a-dbf8-7774eae54742"},"outputs":[],"source":["# Loading pretrained image model from previous experiment\n","img_model = load_model('VGG16_img_model.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9UHaQ4JwfuC5"},"outputs":[],"source":["# Compiling model\n","img_model.compile(loss='binary_crossentropy', optimizer=adam, metrics = [\"accuracy\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LWOvABWHfuC6"},"outputs":[],"source":["# Concatenating the output\n","con_layer = keras.layers.concatenate([txt_model.output, img_model.output])\n","out = Dense(1,activation='sigmoid')(con_layer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vjufrp1nfuC6"},"outputs":[],"source":["# Defining model input and output\n","com_model = Model(inputs = [img_model.input, txt_model.input], outputs=out)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NqxmE9jbfuC6"},"outputs":[],"source":["# Using Stochastic gradient descent with optimizer\n","sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n","com_model.compile(loss='binary_crossentropy', optimizer=adam, metrics = [\"accuracy\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FKofQCKFfuC6"},"outputs":[],"source":["# Plot the model\n","plot_model(com_model, to_file='BiLSTM_VGG_mul_model.png', show_shapes=True, show_layer_names=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zOtFeFJTfuC6","outputId":"afde0e36-30d2-4b4e-91af-398f0f9135e9","scrolled":true},"outputs":[],"source":["# Training model\n","com_model.fit_generator(img_txt_gen_train, epochs=7, validation_steps = 149, steps_per_epoch=2, validation_data=img_txt_gen_val, shuffle=False, class_weight=class_weight)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0FTL0qXlfuC7"},"outputs":[],"source":["# Saving the text model\n","com_model.save('BiLSTM_VGG_mul_model.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DAFcJwETfuC7"},"outputs":[],"source":["# Predicting the label using combined model\n","y_pred_com = (com_model.predict_generator(img_txt_gen_test,steps = 149))\n","y_pred_com = np.round(list(itertools.chain(*y_pred_com)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M9Ttx0-ffuC7","outputId":"f87554be-6b2a-4d3d-f3cb-6c2fb2f1e6d8"},"outputs":[],"source":["# Block for confusion matrix\n","labels = [1,0]\n","cm = confusion_matrix(y_true, y_pred_com, labels)\n","ax= plt.subplot()\n","sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n","\n","# labels, title and ticks\n","ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n","ax.set_title('Confusion Matrix'); \n","ax.xaxis.set_ticklabels(['offensive', 'non-offensive']); ax.yaxis.set_ticklabels(['offensive', 'non-offensive']);"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xqJxwia0fuC7","outputId":"ff463e54-2e04-457a-afba-436aa65b6360","scrolled":true},"outputs":[],"source":["# training accuracy\n","plt.plot(com_model.history.epoch, com_model.history.history['acc'])\n","plt.plot(txt_model.history.epoch, txt_model.history.history['acc'])\n","plt.gca().legend(('meme model acc', 'image model acc', 'text model acc'))\n","plt.xlabel('epoch')\n","plt.ylabel('training accuracy')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l3RRxIjgfuC8","outputId":"32aa4a42-1d38-49e7-bbc0-b39f08a478b6","scrolled":true},"outputs":[],"source":["# Validation Accuracy\n","plt.plot(com_model.history.epoch, com_model.history.history['val_acc'])\n","plt.plot(txt_model.history.epoch, txt_model.history.history['val_acc'])\n","plt.gca().legend(('meme model validation acc', 'image model validation acc', 'text model validation acc'))\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"daGkiEPyfuC8","outputId":"b608db1f-9be5-4ff6-dcd5-5e8afbf440d4"},"outputs":[{"data":{"text/plain":["['loss', 'acc']"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["com_model.metrics_names"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YlbiQdjOfuC8","outputId":"b9e28df1-3377-458e-d5be-9a32a9eec02c"},"outputs":[],"source":["com_model.evaluate_generator(img_txt_gen_test, steps=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EdOIRH6-fuC9","outputId":"3fc9c877-8842-4ade-dd26-ce5f9d311fee"},"outputs":[],"source":["img_model.evaluate_generator(img_gen_test, steps=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rUZNcugjfuC9","outputId":"8502e7ea-e1b8-4b4c-ab2f-ae460c6eb958"},"outputs":[],"source":["txt_model.evaluate_generator(txt_gen_test, steps=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hX22S1o8fuC9"},"outputs":[],"source":["from sklearn.metrics import precision_recall_fscore_support"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"stHXZ2RdfuC9","outputId":"aa050926-37aa-4b6f-b0bd-7a51bc382743"},"outputs":[],"source":["# for txt\n","precision_recall_fscore_support(y_true, y_pred_txt, beta=1.0, labels=None, pos_label=1, average=None)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t3hsH9OAfuC9","outputId":"77ac2c80-5d0e-4ee2-f9f1-85b8d23888c5"},"outputs":[],"source":["# com model\n","precision_recall_fscore_support(y_true, y_pred_com, beta=1.0, labels=None, pos_label=1, average=None)"]}],"metadata":{"colab":{"name":"BiLSTM_VGG16.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":0}
