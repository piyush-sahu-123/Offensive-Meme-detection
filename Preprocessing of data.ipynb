{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"oqHimc-xrSEx"},"outputs":[],"source":["# -*- coding: utf-8 -*-\n","\"\"\"Copy of Multimodal_baseline_Functions.ipynb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"10YyC58NrSE3"},"outputs":[],"source":["# Automatically generated by Colaboratory."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hxNjhHeJrSE4"},"outputs":[],"source":["# Original file is located at\n","#     https://colab.research.google.com/drive/126BdzgXeJIWxbA-W2EfM6kdUKvtL0oPi\n","# \"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bh_N-mu7rSE4"},"outputs":[],"source":["#!/usr/bin/env python\n","# coding: utf-8"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23662,"status":"ok","timestamp":1648038114055,"user":{"displayName":"Piyush Sahu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIRZVhjJg7F6WZp0sW1hzT60y3X4RFPq3FbuvhaQ=s64","userId":"13759545479013218400"},"user_tz":-330},"id":"Kyd8URmmrSE5","outputId":"5cd88da8-886f-418e-da4a-846e901b5dd4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4575,"status":"ok","timestamp":1648038122621,"user":{"displayName":"Piyush Sahu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIRZVhjJg7F6WZp0sW1hzT60y3X4RFPq3FbuvhaQ=s64","userId":"13759545479013218400"},"user_tz":-330},"id":"y-qD6M7PrUmM","outputId":"128462c1-58e7-45d5-b9a1-4441a296f42a"},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"data":{"text/plain":["True"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","from sklearn.preprocessing import LabelEncoder\n","import re\n","from nltk.corpus import stopwords\n","# from nltk import word_tokenize\n","from keras.preprocessing import image\n","from keras.applications.vgg16 import VGG16\n","from keras.applications.inception_v3 import InceptionV3\n","from keras.applications.vgg16 import preprocess_input\n","from keras.preprocessing.text import Tokenizer\n","import numpy as np\n","from keras.layers import Dense, GlobalAveragePooling2D, Embedding, LSTM, multiply\n","from keras.models import Model\n","from keras import preprocessing, Input\n","import os\n","import itertools\n","import numpy as np\n","from PIL import Image, ImageFile\n","\n","import nltk\n","nltk.download('stopwords')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XsGKLtAxrSE7"},"outputs":[],"source":["STOPWORDS = set(stopwords.words('english'))\n","REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n","BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n","EMAIL = re.compile('^([a-zA-Z0-9_\\-\\.]+)@([a-zA-Z0-9_\\-\\.]+)\\.([a-zA-Z]{2,5})$')\n","# NUMBERS = re.compile(['0-9'])\n","STOPWORDS = set(stopwords.words('english'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Tis-ycYrcsa"},"outputs":[],"source":["\n","Training_path = \"./drive/MyDrive/sumaiya thaseen proj/Split Dataset/Training_meme_dataset.csv\"\n","Validation_path = \"./drive/MyDrive/sumaiya thaseen proj/Split Dataset/Validation_meme_dataset.csv\"\n","Testing_path = \"./drive/MyDrive/sumaiya thaseen proj/Split Dataset/Testing_meme_dataset.csv\"\n","img_dir = \"./drive/MyDrive/sumaiya thaseen proj/Labelled Images\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EsIWeDWgrSE9"},"outputs":[],"source":["# For vectors\n","# \"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YotMKXRArSE-"},"outputs":[],"source":["maxlen = 1000"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NZtB17a-rwtd"},"outputs":[],"source":["\n","#doing label encoding for label columns\n","def encode_label(DataFrame, Label_col):\n","    t_y = DataFrame[Label_col].values\n","    Encoder = LabelEncoder()\n","    y = Encoder.fit_transform(t_y)\n","    DataFrame[Label_col] = y\n","    \n","def clean_text(text):\n","    \"\"\"\n","        text: a string\n","        \n","        return: modified initial string\n","    \"\"\"\n","    #preprocessing string \n","    #removing symbols, putting in lowercase and joining it\n","    #while removing \n","    text = text.lower()\n","    text = EMAIL.sub('', text)\n","#     text = NUMBERS.sub('',text)\n","    text = REPLACE_BY_SPACE_RE.sub(' ',text)\n","    text = BAD_SYMBOLS_RE.sub('',text)    \n","    text = text.replace('x','')\n","    text = ' '.join(word for word in text.split() if word not in STOPWORDS)\n","    \n","    return text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t0tO3MbFr0LV"},"outputs":[],"source":["# taking img name and adding\n","# root(folder)/img_name and\n","# storing into array\n","def create_img_array(img_dirct):\n","    all_imgs = []\n","    for root, j, files in os.walk(img_dirct):\n","        for file in files:\n","            file = root + '/' + file\n","            all_imgs.append(file)\n","    return all_imgs\n","\n","def create_img_path(DF, Col_name, img_dir):\n","    img_path = [img_dir + '/' + name for name in DF[Col_name]]\n","    return img_path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mUVEQanarSFB"},"outputs":[],"source":["\n","def preprocess_text(Training_path,Validation_path, Testing_path):\n","    # function to preprocess input\n","    training_DF = pd.read_csv(Training_path, sep = ',')\n","    validation_DF = pd.read_csv(Validation_path, sep = ',')\n","    testing_DF = pd.read_csv(Testing_path, sep = ',')\n","\n","    # encoding all the labels \n","    encode_label(testing_DF,'label')\n","    encode_label(training_DF, 'label')\n","    encode_label(validation_DF, 'label')\n","    clean_text(training_DF['sentence'][0])\n","\n","    # Processing the text\n","    training_DF['sentence'] = training_DF['sentence'].apply(clean_text)\n","    testing_DF['sentence'] = testing_DF['sentence'].apply(clean_text)\n","    validation_DF['sentence'] = validation_DF['sentence'].apply(clean_text)\n","    return training_DF, testing_DF, validation_DF"]},{"cell_type":"markdown","metadata":{"id":"3Xk8trWgrSFB"},"source":["\n","In[8]:<br>\n","Function that returns image reading from the path<br>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2MZrEepDrSFB"},"outputs":[],"source":["def get_input(path):\n","    # Loading image from given path\n","    # and resizing it to 224*224*3 format\n","    ImageFile.LOAD_TRUNCATED_IMAGES = True\n","    img = image.load_img(path, target_size=(224,224))    \n","    return(img)"]},{"cell_type":"markdown","metadata":{"id":"oEp_qsg6rSFC"},"source":["\n","Function to get the output<br><br>\n","returns an array of labels<br>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hzB2uGVZrSFC"},"outputs":[],"source":["def get_output(path,label_file=None):\n","    # Spliting the path and take out the image id    \n","    filename = path.split('/')[-1]\n","    # Taking list of labels\n","    labels = list(label_file[label_file['image_name'] == filename]['label'].values)\n","    # for duplicate selecting labels\n","    if len(labels) <= 2:\n","        label = labels[0]\n","    elif len(labels) > 2:\n","        uni_label = list(set(labels))\n","        count_label = [labels.count(lab) for lab in uni_label]\n","        lab_idx = count_label.index(max(count_label))\n","        label = uni_label[lab_idx]\n","    return label"]},{"cell_type":"markdown","metadata":{"id":"0lmj4qTXrSFC"},"source":["\n","Takes in image and preprocess it\n","n[134]:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EFPVn5k9sNsD"},"outputs":[],"source":["def process_input(img):\n","    # Converting image to array    \n","    img_data = image.img_to_array(img)\n","    # Adding one more dimension to array    \n","    img_data = np.expand_dims(img_data, axis=0)\n","    #     \n","    img_data = preprocess_input(img_data)\n","    return(img_data)"]},{"cell_type":"markdown","metadata":{"id":"ca2FX1jgsVGl"},"source":["Function to generate the data\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KlKBcM27rSFD"},"outputs":[],"source":["def image_generator(files,label_file, batch_size = None):   \n","    idxs = list(range(len(files)))\n","    idx = 0\n","    while True: \n","        batch_paths = files[idx:idx+batch_size]\n","        batch_input = [] # Batch input initialization\n","        batch_output = [] # Batch output initialization\n","          \n","        # Read in each input, perform preprocessing and get labels    \n","        for input_path in batch_paths:\n","            input = get_input(input_path ) # Load image\n","            output = get_output(input_path,label_file=label_file ) # Load label of the image\n","            input = process_input(img=input) # Process the image\n","            batch_input.append(input[0]) # Append the image\n","            batch_output.append(output)  # Append the label\n","            \n","        # Return a tuple of (input,output) to feed the network\n","        batch_x = np.array( batch_input )\n","        batch_y = np.array( batch_output )\n","        if len(batch_x) < batch_size:\n","            idx = 0\n","        else:             \n","            yield (batch_x, batch_y)"]},{"cell_type":"markdown","metadata":{"id":"j1XiqSPPrSFD"},"source":["\n","In[10]:\n","<br>\n","  \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0JLZwTy2s3iB"},"outputs":[],"source":["\n","def text_generator(padded_seq, y, batch_size=None):\n","    \"\"\"\n","        padded_seq: vectorized padded text sequence \n","        y: label of the text\n","        batch_size: Number of observations to be selected at a time\n","        \n","        return: generator object of text data\n","    \"\"\"\n","    idxs = list(range(len(y)))\n","    idx = 0\n","    while True:\n","        batch_idxs = idxs[idx:idx+batch_size]\n","        idx = idx + batch_size\n","#         batch_idxs = np.random.choice(a = list(range(len(padded_seq))), size=batch_size) #Selecting the random batch indexes    \n","        batch_input = [] # Initializing batch input\n","        batch_output = [] # Initializing batch output\n","        \n","        # Traversing through the batch indexes\n","        for batch_idx in batch_idxs:\n","            input = padded_seq[batch_idx] # selecting padded sequences from the batch\n","            output = y[batch_idx] # Selecting label            \n","            batch_input.append(input) # Appending the input (text vector)\n","            batch_output.append(output) # Appending the label\n","        \n","        # Return a tuple of (input,output) to feed the network\n","        batch_x = np.array( batch_input )\n","        batch_y = np.array( batch_output )\n","        if len(batch_x) < batch_size:\n","            idx = 0\n","        else:             \n","            yield (batch_x, batch_y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SIL763kntcSZ"},"outputs":[],"source":["def img_text_generator(files, padded_seq, y, batch_size=None):\n","    \"\"\"\n","        padded_seq: vectorized padded text sequence \n","        y: label of the text\n","        batch_size: Number of observations to be selected at a time\n","        \n","        return: generator object of text data\n","    \"\"\"\n","    while True:\n","        batch_idxs = np.random.choice(a = list(range(len(padded_seq))), size=batch_size) #Selecting the random batch indexes    \n","        batch_input_txt = [] # Initializing batch input text\n","        batch_input_img = [] # Initializing batch input image\n","        batch_output = [] # Initializing batch output\n","        \n","        # Traversing through the batch indexes\n","        for batch_idx in batch_idxs:\n","            input_txt = padded_seq[batch_idx] # selecting padded sequences from the batch\n","            output = y[batch_idx] # Selecting label  \n","            input_img = get_input(files[batch_idx])\n","            input_img = process_input(input_img)\n","            batch_input_txt.append(input_txt) # Appending the input (text vector)\n","            batch_input_img.append(input_img[0])\n","            batch_output.append(output) # Appending the label\n","        \n","        # Return a tuple of (input,output) to feed the network\n","        batch_x1 = np.array( batch_input_img )\n","        batch_x2 = np.array( batch_input_txt )\n","        batch_y = np.array( batch_output )\n","        yield ([batch_x1, batch_x2], batch_y)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SMHq_LPEuu74"},"outputs":[],"source":[]}],"metadata":{"colab":{"name":"preprocessing.ipynb","provenance":[{"file_id":"1N2JpgW2usUjrF_6MhsZ1wTC8A4sJWHoC","timestamp":1648059022778}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":0}
