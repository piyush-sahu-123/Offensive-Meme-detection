{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ejQZmv9YfW9O"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v9xJH5StfUcD","outputId":"b8aa14b1-73ca-4b3c-af60-729304f3ee8b","scrolled":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Using TensorFlow backend.\n"]}],"source":["# Importing all the necessary libraries\n","import keras\n","import h5py\n","from keras import optimizers\n","from keras.models import load_model\n","from keras.layers import Bidirectional\n","from Multimodal_baseline_Functions import *\n","from keras.layers.core import Reshape, Dropout\n","from keras.utils.vis_utils import plot_model\n","import os\n","# import keras_metrics\n","import matplotlib.pyplot as plt\n","from keras.layers import Conv1D, MaxPooling1D, Flatten, GlobalAveragePooling3D\n","from keras import regularizers\n","import seaborn as sns\n","import matplotlib.pyplot as plt   \n","from sklearn.metrics import confusion_matrix\n","from keras import regularizers  \n","from keras.applications.inception_v3 import InceptionV3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3TQAE4RbfZdT"},"outputs":[],"source":["from Preprocessing of data import *"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_0TJP2JrfUcJ"},"outputs":[],"source":["# Storing directory of glove embeddings\n","GLOVE_DIR = \"./drive/MyDrive/sumaiya thaseen proj/glove.6B\"\n","EMBEDDING_DIM = 50"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"teI3hri6fUcJ"},"outputs":[],"source":["# Assigning class weights\n","class_weight = {1: 1.4,\n","                0: 1.}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hJdrFgKrfUcK"},"outputs":[],"source":["# Defining model with Adam optimizer\n","adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n","sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n","adadelta = optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WKsCEGsnfUcK"},"outputs":[],"source":["def Image_model(base_model):\n","    # Freezing all the trainable layers\n","    for layer in base_model.layers:\n","        layer.trainable = False\n","\n","    # Creating output layer\n","    x = base_model.output\n","    # Adding pooling layer before the output\n","    x = GlobalAveragePooling2D()(x)\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M2nZiQGNfUcL"},"outputs":[],"source":["def read_data(file_name):\n","  #Opening file\n","    with open(file_name,'r', encoding=\"utf8\") as f:\n","      #Creating empty set and dictonary for vocab and word respectively\n","        word_vocab = set() \n","        word2vector = {}\n","        #Iterating over each line of file\n","        for line in f:\n","            #Spliting lines\n","            line_ = line.strip() \n","            #Splitting words\n","            words_Vec = line_.split()            \n","            word_vocab.add(words_Vec[0])\n","            word2vector[words_Vec[0]] = np.array(words_Vec[1:],dtype=float)\n","    print(\"Total Words in DataSet:\",len(word_vocab))\n","    return word_vocab,word2vector"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cf1zzUJwfUcM"},"outputs":[],"source":["# Dividing data in test, train, validation\n","training_DF, testing_DF, validation_DF = preprocess_text(Training_path,Validation_path, Testing_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vZ2KiJoQfUcM"},"outputs":[],"source":["# Processing image and text for each set\n","# Creating train, test and validation image path\n","train_img_path = create_img_path(training_DF,'image_name', img_dir)\n","test_img_path = create_img_path(testing_DF,'image_name', img_dir)\n","val_img_path = create_img_path(validation_DF,'image_name', img_dir)\n","\n","# Processing the text\n","training_DF['sentence'] = training_DF['sentence'].apply(clean_text)\n","testing_DF['sentence'] = testing_DF['sentence'].apply(clean_text)\n","validation_DF['sentence'] = validation_DF['sentence'].apply(clean_text)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e6-x-RBCfUcN"},"outputs":[],"source":["# Vectorising text\n","# process the whole observation into single list\n","train_text_list=list(training_DF['sentence'])\n","test_text_list = list(testing_DF['sentence'])\n","val_text_list = list(validation_DF['sentence'])\n","\n","# Creating vectors for train, test, validation\n","tokenizer = Tokenizer(num_words=1000)\n","tokenizer.fit_on_texts(train_text_list)\n","sequences_train = tokenizer.texts_to_sequences(train_text_list)\n","sequences_test = tokenizer.texts_to_sequences(test_text_list)\n","sequences_val = tokenizer.texts_to_sequences(val_text_list)\n","\n","x_train = preprocessing.sequence.pad_sequences(sequences_train, maxlen=maxlen)\n","x_test = preprocessing.sequence.pad_sequences(sequences_test, maxlen=maxlen)\n","x_val = preprocessing.sequence.pad_sequences(sequences_val, maxlen=maxlen)\n","\n","# encoding all the labels \n","y_test = testing_DF['label']\n","y_train = training_DF['label']\n","y_val = validation_DF['label']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OcSVZeX6fUcO"},"outputs":[],"source":["# Creating train, test, val, generator for meme\n","img_txt_gen_train = img_text_generator(train_img_path, x_train, y_train, batch_size=32)\n","img_txt_gen_test = img_text_generator(test_img_path, x_test, y_test, batch_size=1)\n","img_txt_gen_val = img_text_generator(val_img_path, x_val, y_val, batch_size=1)\n","\n","# Creating train, test, val, generator for text\n","txt_gen_train = text_generator(x_train, y_train, batch_size=32)\n","txt_gen_test = text_generator(x_test, y_test, batch_size=1)\n","txt_gen_val = text_generator(x_val, y_val, batch_size=1)\n","\n","# Creating train, test, val, generator for image\n","img_gen_train = image_generator(train_img_path, training_DF, batch_size=32)\n","img_gen_test = image_generator(test_img_path, testing_DF, batch_size=1)\n","img_gen_val = image_generator(val_img_path, validation_DF, batch_size=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cZ_ho8EpfUcO","outputId":"9505824b-eb91-49be-ae91-8866fa930c9e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total Words in DataSet: 400000\n"]}],"source":["# Creating vocabulary with glove embeddings\n","vocab, w2v = read_data(os.path.join(GLOVE_DIR, \"glove.6B.50d.txt\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CKa6cTdIfUcP"},"outputs":[],"source":["# Creating word index\n","word_index = tokenizer.word_index\n","num_tokens = len(word_index)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HHEMV2tTfUcP"},"outputs":[],"source":["#Creating embeddding weight matrix\n","embedding_matrix = np.zeros((num_tokens + 1, EMBEDDING_DIM))\n","\n","for word, i in word_index.items():\n","    embedding_vector = w2v.get(word)\n","    if embedding_vector is not None:\n","        embedding_matrix[i] = embedding_vector"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Opm352QJfUcP","outputId":"822c50c0-ec0e-4b24-9db3-9955449844d2"},"outputs":[],"source":["#Creating embedded layer using embedded matrix as weight matrix\n","embedding_layer = Embedding(num_tokens + 1, EMBEDDING_DIM, weights=[embedding_matrix], trainable = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IuZCFCVcfUcQ","outputId":"ccd6dbd4-3c62-43e8-f582-e5ed5160de77"},"outputs":[],"source":["# Defining input layer\n","main_input = Input(shape=(maxlen,), dtype='int32', name='main_input')\n","\n","# Defining embedding layer which will encode the input sequence\n","embedded_sequences = embedding_layer(main_input)\n","\n","# A LSTM will transform the vector sequence into a single vector,\n","# containing information about the entire sequence\n","lstm1 = LSTM(32, return_state=True)\n","encoder_outputs,state_h,state_c = (lstm1)(embedded_sequences)\n","states= [state_h,state_c]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C4MH4KQ1fUcQ"},"outputs":[],"source":["# Defining second LSTM\n","lstm2=LSTM(32, return_sequences=True, return_state=True)\n","# Adding initial state as state of  previous LSTM\n","decoder_out,_,_=lstm2(embedded_sequences,initial_state=states)\n","# Adding dense layer with 500 neurons\n","decoder_dense = (Dense(500, activation='relu'))\n","# LSTM output\n","lstm_out=(decoder_out)\n","# Flattening \n","lstm_out = Flatten()(lstm_out)\n","# Output of text model\n","txt_out = Dense(1, activation='sigmoid')(lstm_out)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JS8I1H2dfUcQ"},"outputs":[],"source":["# Defining text model\n","txt_model = Model(inputs = [main_input], outputs=txt_out)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UV6zYe-mfUcR","scrolled":true},"outputs":[],"source":["# compiling text model\n","txt_model.compile(loss='binary_crossentropy', optimizer=adam, metrics = [\"accuracy\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fiS0eE9tfUcR"},"outputs":[],"source":["# Plotting the text model\n","plot_model(txt_model, to_file='Stack_LSTM_txt_model.png', show_shapes=True, show_layer_names=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s1ru6f9mfUcR","outputId":"b747dde1-9b27-4685-a96e-d45843bf9689","scrolled":true},"outputs":[],"source":["# Training text model\n","txt_model.fit_generator(txt_gen_train, epochs=7, validation_steps = 149, steps_per_epoch=2, validation_data=txt_gen_val, shuffle = False, class_weight=class_weight)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4jdLUguTfUcR","outputId":"98e06439-302f-4d6d-8909-12e65f08e15e"},"outputs":[],"source":["# Saving text model\n","txt_model.save('Stack_LSTM_txt_model.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mGW6oPzLfUcS"},"outputs":[],"source":["# Predicting labels of the test set\n","y_pred_txt = (txt_model.predict_generator(txt_gen_test,steps = 149))\n","y_pred_txt = np.round(list(itertools.chain(*y_pred_txt)))\n","# Defining true labels\n","y_true = y_test.values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kIRwjht9fUcS"},"outputs":[],"source":["# Block that prints confusion matrix\n","labels = [1,0]\n","cm = confusion_matrix(y_true, y_pred_txt, labels)\n","ax= plt.subplot()\n","sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n","\n","# labels, title and ticks\n","ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n","ax.set_title('Confusion Matrix'); \n","ax.xaxis.set_ticklabels(['offensive', 'non-offensive']); ax.yaxis.set_ticklabels(['offensive', 'non-offensive']);"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TvU_8pUWfUcS","outputId":"8d48ad79-80d3-4525-a320-7abfb6342f94","scrolled":true},"outputs":[],"source":["# create base model with imagenet weights\n","pre_trained_image_model = VGG16(weights='imagenet', include_top=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kjmyd5pefUcT"},"outputs":[],"source":["# Building img_prediction layer using Image_model\n","base_img = Image_model(pre_trained_image_model)\n","img_prediction_layer = Dense(1, activation='sigmoid')(base_img)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5SaG3WuIfUcT"},"outputs":[],"source":["# Defining image model\n","img_model = Model(inputs = [pre_trained_image_model.input], outputs=img_prediction_layer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Aw8V4QFCfUcT"},"outputs":[],"source":["# Compiling image model\n","img_model.compile(loss='binary_crossentropy', optimizer=adam, metrics = [\"accuracy\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u-V94qxLfUcT"},"outputs":[],"source":["# Plotting image model\n","plot_model(img_model, to_file='VGG16_img_model.png', show_shapes=True, show_layer_names=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hok1fg81fUcT","outputId":"30d8088e-126d-458c-858c-a9e6b590e793","scrolled":false},"outputs":[],"source":["# Training image model\n","img_model.fit_generator(img_gen_train, epochs=7, validation_steps = 149, steps_per_epoch=2, validation_data=img_gen_val, shuffle=False, class_weight=class_weight)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VygEorMJfUcT"},"outputs":[],"source":["# Saving image model\n","img_model.save('VGG16_img_model.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tbCI2sz5fUcU"},"outputs":[],"source":["# Predicting labels using image model\n","y_pred_img = (img_model.predict_generator(img_gen_test,steps = 149))\n","y_pred_img = np.round(list(itertools.chain(*y_pred_img)))\n","y_true = y_test.values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u7Pk5oI8fUcU"},"outputs":[],"source":["# Confusion matrix for image classifier\n","labels = [1,0]\n","cm = confusion_matrix(y_true, y_pred_img, labels)\n","ax= plt.subplot()\n","sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n","\n","# labels, title and ticks\n","ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n","ax.set_title('Confusion Matrix'); \n","ax.xaxis.set_ticklabels(['offensive', 'non-offensive']); ax.yaxis.set_ticklabels(['offensive', 'non-offensive']);"]},{"cell_type":"markdown","metadata":{"id":"4SLmfC3cex4L"},"source":["combining models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xR2jUkpjfUcU"},"outputs":[],"source":["txt_model.compile(loss='binary_crossentropy', optimizer=adam, metrics = [\"accuracy\"])\n","img_model.compile(loss='binary_crossentropy', optimizer=adam, metrics = [\"accuracy\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U-cFU9KxfUcU"},"outputs":[],"source":["# Concatenating output of both classifiers\n","con_layer = keras.layers.concatenate([txt_model.output, img_model.output])\n","out = Dense(1,activation='sigmoid')(con_layer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PZQWAqtNfUcU"},"outputs":[],"source":["# Defining model input and output\n","com_model = Model(inputs = [img_model.input, txt_model.input], outputs=out)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mTBWf0EKfUcV"},"outputs":[],"source":["# Using Stochastic gradient descent with optimizer\n","sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n","com_model.compile(loss='binary_crossentropy', optimizer=adam, metrics = [\"accuracy\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iJHhUrydfUcV"},"outputs":[],"source":["# PlotTing combined model\n","plot_model(com_model, to_file='Stack_LSTM_VGG_mul_model.png', show_shapes=True, show_layer_names=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TI2OQIc5fUcV","outputId":"5e0098ee-2dc2-4a81-a832-6fd7f716b10a","scrolled":true},"outputs":[],"source":["# Training model\n","com_model.fit_generator(img_txt_gen_train, epochs=7, validation_steps = 149, steps_per_epoch=2, validation_data=img_txt_gen_val, shuffle=False, class_weight=class_weight)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"do1XTw3HfUcV","outputId":"7563d187-f518-49e5-910e-09aaabfdc40b"},"outputs":[],"source":["# Saving combined model\n","com_model.save('Stack_LSTM_VGG_mul_model.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"127-gRdUfUcV"},"outputs":[],"source":["y_pred_com = (com_model.predict_generator(img_txt_gen_test,steps = 149))\n","y_pred_com = np.round(list(itertools.chain(*y_pred_com)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rwz5FMDOfUcV"},"outputs":[],"source":["labels = [1,0]\n","cm = confusion_matrix(y_true, y_pred_com, labels)\n","ax= plt.subplot()\n","sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n","\n","# labels, title and ticks\n","ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n","ax.set_title('Confusion Matrix'); \n","ax.xaxis.set_ticklabels(['offensive', 'non-offensive']); ax.yaxis.set_ticklabels(['offensive', 'non-offensive']);"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tytln6O1fUcW","scrolled":true},"outputs":[],"source":["# Plotting training accuaracy \n","plt.plot(com_model.history.epoch, com_model.history.history['acc'])\n","plt.plot(txt_model.history.epoch, txt_model.history.history['acc'])\n","plt.gca().legend(('meme model acc', 'image model acc', 'text model acc'))\n","plt.xlabel('epoch')\n","plt.ylabel('training accuracy')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8IJ4ord2fUcW","scrolled":false},"outputs":[],"source":["# Plotting validation accuracy\n","plt.plot(com_model.history.epoch, com_model.history.history['val_acc'])\n","plt.plot(txt_model.history.epoch, txt_model.history.history['val_acc'])\n","plt.gca().legend(('meme model validation acc', 'image model validation acc', 'text model validation acc'))\n","plt.xlabel('epoch')\n","plt.ylabel('validaion accuracy')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HFTRXV5ffUcW","outputId":"19841bc5-3c31-4566-cf01-a99255368049"},"outputs":[],"source":["# Evaluating model by calculating loss and accuracy respectively\n","# for combined model\n","com_model.evaluate_generator(img_txt_gen_test, steps=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VpjK8UcwfUcW","outputId":"f829abf2-f4c0-4fae-8346-5d5680b4662e"},"outputs":[],"source":["# loss and accuracy for text model\n","txt_model.evaluate_generator(txt_gen_test, steps=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gt23D-zLfUcX","outputId":"5820cbc2-ce8a-4059-c0ef-0ee815b2bc4b"},"outputs":[],"source":["# Loss and accuracy for image model\n","img_model.evaluate_generator(img_gen_test, steps=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IlzqyDfVfUcX"},"outputs":[],"source":["from sklearn.metrics import precision_recall_fscore_support"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rd4AirCxfUcX","outputId":"611de305-2b85-41eb-fcc0-8bb315d3aeb1"},"outputs":[],"source":["# for txt\n","precision_recall_fscore_support(y_true, y_pred_txt, beta=1.0, labels=None, pos_label=1, average=None)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2tDOSJmwfUcX","outputId":"9233944b-380d-4278-c33f-acc023761f90"},"outputs":[],"source":["# for image\n","precision_recall_fscore_support(y_true, y_pred_img, beta=1.0, labels=None, pos_label=1, average=None)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V__3A4pvfUcX","outputId":"7005a387-db8b-4e78-ef1b-0297bff12854"},"outputs":[],"source":["# com model\n","precision_recall_fscore_support(y_true, y_pred_com, beta=1.0, labels=None, pos_label=1, average=None)"]}],"metadata":{"colab":{"name":"Stacked_LSTM_VGG16.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":0}
